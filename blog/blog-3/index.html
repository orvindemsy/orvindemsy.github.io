<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Understanding Grid Search/Randomized CV’s (refit=True) | Orvin Demsy</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="generator" content="Hugo 0.77.0" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    
    
      <link href="https://orvindemsy.github.io/portfolio/dist/css/app.4fc0b62e4b82c997bb0041217cd6b979.css" rel="stylesheet">
    

    

    
      

    

    
    
    <meta property="og:title" content="Understanding Grid Search/Randomized CV’s (refit=True)" />
<meta property="og:description" content="In this article I will share my experience and knowledge of implementing hyperparameter tuning with scikit-learn’s GridSearchCV or RandomizedCV. Concretely, I will focus on refit=True parameter as those are the ones that confuses me the most upon early use of GridSearch/RandomizedCV. I hope this article will help you build better understanding on those methods Pre-requisite First off, as prerequisite a basic understanding in the following topics are expected:
 K-Fold CV Training a model Hyperparameters  I will try to explain briefly here, but I encourage you to read up information about it yourself." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://orvindemsy.github.io/portfolio/blog/blog-3/" />
<meta property="article:published_time" content="2020-10-03T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-10-03T00:00:00+00:00" />
<meta itemprop="name" content="Understanding Grid Search/Randomized CV’s (refit=True)">
<meta itemprop="description" content="In this article I will share my experience and knowledge of implementing hyperparameter tuning with scikit-learn’s GridSearchCV or RandomizedCV. Concretely, I will focus on refit=True parameter as those are the ones that confuses me the most upon early use of GridSearch/RandomizedCV. I hope this article will help you build better understanding on those methods Pre-requisite First off, as prerequisite a basic understanding in the following topics are expected:
 K-Fold CV Training a model Hyperparameters  I will try to explain briefly here, but I encourage you to read up information about it yourself.">
<meta itemprop="datePublished" content="2020-10-03T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-10-03T00:00:00+00:00" />
<meta itemprop="wordCount" content="1575">



<meta itemprop="keywords" content="," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Understanding Grid Search/Randomized CV’s (refit=True)"/>
<meta name="twitter:description" content="In this article I will share my experience and knowledge of implementing hyperparameter tuning with scikit-learn’s GridSearchCV or RandomizedCV. Concretely, I will focus on refit=True parameter as those are the ones that confuses me the most upon early use of GridSearch/RandomizedCV. I hope this article will help you build better understanding on those methods Pre-requisite First off, as prerequisite a basic understanding in the following topics are expected:
 K-Fold CV Training a model Hyperparameters  I will try to explain briefly here, but I encourage you to read up information about it yourself."/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://orvindemsy.github.io/portfolio/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Orvin Demsy
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://orvindemsy.github.io/portfolio/about/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://orvindemsy.github.io/portfolio/blog/" title="Blog page">
              Blog
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://orvindemsy.github.io/portfolio/contact/" title="Contacts page">
              Contacts
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://orvindemsy.github.io/portfolio/post/" title="Projects page">
              Projects
            </a>
          </li>
          
        </ul>
      
      







<a href="https://www.linkedin.com/in/orvin-demsy" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="github.com/orvindemsy" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>








    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        BLOG
      </aside>
      




  <div id="sharing" class="mt3">

    
    <a href="https://www.facebook.com/sharer.php?u=https://orvindemsy.github.io/portfolio/blog/blog-3/" class="facebook no-underline" aria-label="share on Facebook">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

    </a>

    
    
    <a href="https://twitter.com/share?url=https://orvindemsy.github.io/portfolio/blog/blog-3/&amp;text=Understanding%20Grid%20Search/Randomized%20CV%e2%80%99s%20%28refit=True%29" class="twitter no-underline" aria-label="share on Twitter">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

    </a>

    
    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://orvindemsy.github.io/portfolio/blog/blog-3/&amp;title=Understanding%20Grid%20Search/Randomized%20CV%e2%80%99s%20%28refit=True%29" class="linkedin no-underline" aria-label="share on LinkedIn">
      <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

    </a>
  </div>


      <h1 class="f1 athelas mt3 mb1">Understanding Grid Search/Randomized CV’s (refit=True)</h1>
      
      
      <time class="f6 mv4 dib tracked" datetime="2020-10-03T00:00:00Z">October 3, 2020</time>

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p>In this article I will share my experience and knowledge of implementing 
hyperparameter tuning with scikit-learn’s GridSearchCV or RandomizedCV. Concretely, I will focus on <code>refit=True</code> parameter as those are the ones that confuses me the most upon early use of GridSearch/RandomizedCV. I hope this article will help you build better understanding on those methods
 </p>
<h2 id="pre-requisite">Pre-requisite</h2>
<p>First off, as prerequisite a basic understanding in the following topics are expected:</p>
<ul>
<li>K-Fold CV</li>
<li>Training a model</li>
<li>Hyperparameters</li>
</ul>
<p>I will try to explain briefly here, but I encourage you to read up information about it yourself.</p>
<!-- raw HTML omitted -->
<h2 id="note">Note</h2>
<p>The focus of this article is stated above, consequently here are things that will be ignored during data processing:</p>
<ul>
<li>Un-normalized features value</li>
<li>The <em>convergence warning</em> due to un-normalized values<br>
If you want to follow this tutorial, I suggest suppressing all warning by executing</li>
</ul>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> warnings
warnings<span style="color:#f92672">.</span>filterwarnings(<span style="color:#e6db74">&#39;ignore&#39;</span>)
</code></pre></div><h2 id="problem-formulation">Problem formulation</h2>
<p>The objective is to find the hyperparameter values of logistic regression model that gives best accuracy for binary classification.</p>
<!-- raw HTML omitted -->
<h2 id="load-dataset">Load dataset</h2>
<p>Let’s use the readily available breast_cancer dataset in scikit-learn package. Let’s import that dataset and other necessary packages</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> load_breast_cancer
<span style="color:#f92672">from</span> sklearn.datasets <span style="color:#f92672">import</span> load_iris
<span style="color:#f92672">import</span> pandas <span style="color:#f92672">as</span> pd
<span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
</code></pre></div><p>Peek at the dataset to see how many features there are, let’s also see how many samples/instances are available on each class</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">dataset <span style="color:#f92672">=</span> load_breast_cancer()
dataset <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(np<span style="color:#f92672">.</span>c_[dataset<span style="color:#f92672">.</span>data, dataset<span style="color:#f92672">.</span>target], columns<span style="color:#f92672">=</span>list(dataset<span style="color:#f92672">.</span>feature_names) <span style="color:#f92672">+</span> [<span style="color:#e6db74">&#39;target&#39;</span>])
dataset<span style="color:#f92672">.</span>head()
</code></pre></div><figure>
    <img src="https://orvindemsy.github.io/portfolio/images/blog/blog-3-refit/dataset_head.png"/> 
</figure>

<!-- raw HTML omitted -->
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">dataset<span style="color:#f92672">.</span>groupby(<span style="color:#e6db74">&#39;target&#39;</span>)<span style="color:#f92672">.</span>size()
</code></pre></div><pre><code>target
0.0    212
1.0    357
dtype: int64
</code></pre><p>So far, we know the dataset contains 569 samples with 30 features, 212 of those are classified as ‘1’ and 357 are classified as ‘0’. Let’s continue to split the data into train and test set.</p>
<!-- raw HTML omitted -->
<h2 id="split-into-train-and-test-set">Split into train and test set</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">X_all <span style="color:#f92672">=</span> dataset<span style="color:#f92672">.</span>iloc[:, :<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
y_all <span style="color:#f92672">=</span> dataset<span style="color:#f92672">.</span>iloc[:, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]

<span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> train_test_split

X_train, X_test, y_train, y_test <span style="color:#f92672">=</span> train_test_split(X_all, y_all, train_size<span style="color:#f92672">=</span><span style="color:#ae81ff">0.6</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">42</span>)

<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;X_train shape:&#39;</span>, X_train<span style="color:#f92672">.</span>shape)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;y_train shape:&#39;</span>,y_train<span style="color:#f92672">.</span>shape)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;X_test shape:&#39;</span>, X_test<span style="color:#f92672">.</span>shape)
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;y_test shape:&#39;</span>,y_test<span style="color:#f92672">.</span>shape)
</code></pre></div><p>Output:</p>
<pre><code>X_train shape: (341, 30)
y_train shape: (341,)
X_test shape: (228, 30)
y_test shape: (228,)
</code></pre><p>Okay, now data preprocessing steps are done. We are ready for the classification stage, first we need to build and train/fit our model into training data.</p>
<blockquote>
<p><em>Possible FAQ so far</em>:<br>
Why set random_state to 42?</p>
<blockquote>
<p>You can set this number to any integer you want, the purpose of setting this random_state is for reproducibility, trivial reason why 42 is often used can be found <a href="https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy">here</a></p>
</blockquote>
</blockquote>
<blockquote>
<p>Why do you set train_size to 0.6?</p>
<blockquote>
<p>Usually, you want to split your data by ration of 7:3 or 8:2 (train:test), objective of this work is different, this is done for explanatory purpose</p>
</blockquote>
</blockquote>
<!-- raw HTML omitted -->
<h2 id="training-the-model">Training the model</h2>
<p>Load the Logistic Regression, define a model, then train the model with our training data</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.linear_model <span style="color:#f92672">import</span> LogisticRegression

model_no_tune <span style="color:#f92672">=</span> LogisticRegression(max_iter<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>)

model_no_tune<span style="color:#f92672">.</span>fit(X_train, y_train)
</code></pre></div><p>Output:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">LogisticRegression(C<span style="color:#f92672">=</span><span style="color:#ae81ff">1.0</span>, class_weight<span style="color:#f92672">=</span>None, dual<span style="color:#f92672">=</span>False, fit_intercept<span style="color:#f92672">=</span>True,
                   intercept_scaling<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, l1_ratio<span style="color:#f92672">=</span>None, max_iter<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>,
                   multi_class<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;auto&#39;</span>, n_jobs<span style="color:#f92672">=</span>None, penalty<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;l2&#39;</span>,
                   random_state<span style="color:#f92672">=</span>None, solver<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;lbfgs&#39;</span>, tol<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0001</span>, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>,
                   warm_start<span style="color:#f92672">=</span>False)
</code></pre></div><p>The lengthy things inside the parentheses following <code>LogisticRegression</code> is the initial deafult parameters of the model, some of them are hyperparameters whose values can be set according to our will. As an example, I set the <code>max_iter</code> value to 10.</p>
<p>For this article let’s focus on two hyperparameters namely, <code>C</code> and <code>max_iter</code>. We’ll find the best values for these in the later section.</p>
<p>Then let’s see how it performs on test data</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">model_no_tune<span style="color:#f92672">.</span>score(X_test, y_test)
</code></pre></div><p>Output:</p>
<pre><code>0.9517543859649122
</code></pre><p>Good, 0.95 not bad at all. But is this really the best the model can give? Nope, remember we can tune the hyperparameters, but first let’s review what happens when model is trained. 
 </p>
<h2 id="what-happens-when-we-train-the-model">What happens when we train the model?</h2>
<p>This is where I expect you to have a knowledge of what happens when we train the model, knowledge of logistic regression might be helpful too.</p>
<p>Remember that when we train the model, we feed into the model our training data (<code>X_test</code>) and the target (<code>y_test</code>). <strong>The model will learn the weights/parameters (usually denoted by $\theta$) that best fitted those data</strong>. n is determined by numbers of features. So, if there are 30 features in our data there will be 30 weights in our model. Let&rsquo;s confirm there are 30 weights in our model.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">model_no_tune<span style="color:#f92672">.</span>coef_
</code></pre></div><p>Output:</p>
<pre><code>array([[ 2.89479065e-03,  5.25384007e-03,  1.76541312e-02,
         2.17186403e-02,  3.03361474e-05,  9.22071112e-06,
        -1.94952117e-05, -9.80070124e-06,  5.62485250e-05,
         2.28559189e-05,  1.53327500e-05,  4.05040997e-04,
         9.31758108e-05, -6.20673739e-03,  2.54362610e-06,
         3.87518114e-06,  3.89117211e-06,  1.87377855e-06,
         6.56052693e-06,  1.17953472e-06,  2.78523885e-03,
         6.59304644e-03,  1.69345600e-02, -2.10331333e-02,
         3.90652953e-05,  6.69649802e-06, -2.94063588e-05,
        -5.77885791e-06,  7.76807859e-05,  2.53727980e-05]])
</code></pre><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">model_no_tune<span style="color:#f92672">.</span>coef_<span style="color:#f92672">.</span>shape
</code></pre></div><p>Output</p>
<pre><code>(1, 30)
</code></pre><p>Yes, we can see there are 30 numbers of weights/parameters in the model.
There is also a bias value that we can see by calling</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">model_no_tune<span style="color:#f92672">.</span>coef_<span style="color:#f92672">.</span>shape
</code></pre></div><p>Output:</p>
<pre><code>array([0.00036287])
</code></pre><p>I need you to pay attention to these weights because <strong>different set of training data or different set of hyperparameters values, will gives different weights values.</strong></p>
<!-- raw HTML omitted -->
<h2 id="k-fold-cross-validation-review">K-Fold Cross Validation Review</h2>
<p>In k-fold cv we split the data into n-fold, then we will train the data on n-1 set (equivalent to training data) and evaluate the score on 1 set (equivalent to test data). Notice that this means each set should produce different set of model weights/parameters. Here’s an illustration of 3-fold cross validation.</p>
<figure>
    <img src="https://orvindemsy.github.io/portfolio/images/blog/blog-3-refit/cvfold3.jpg"/> 
</figure>

<p>The values of model weights set 1 is not equal to 2 or 3, vice versa. The takeaway is the model weights/parameters value depends on which training data and hyperparameters value it is being trained on.</p>
<h2 id="training-with-gridsearchcv">Training with GridSearchCV</h2>
<p>Now it&rsquo;s time to set up our hyperparameters values, by convention you are expected to create a dictionary whose key corresponds to the model’s hyperpameters, recall that we want to adjust <code>C</code> and <code>max_iter</code> values of <code>model_no_tune</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">from</span> sklearn.model_selection <span style="color:#f92672">import</span> GridSearchCV

parameters <span style="color:#f92672">=</span> {
    <span style="color:#e6db74">&#39;C&#39;</span>: [<span style="color:#ae81ff">0.1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>],
    <span style="color:#e6db74">&#39;max_iter&#39;</span> : [<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">1000</span>]
}
</code></pre></div><p>GridSearchCV will set up pairs of parameters defined in the dictionary and use them as model parameters, in this example there will be 9 pairs:</p>
<table>
<thead>
<tr>
<th style="text-align:center">Pair no.</th>
<th style="text-align:left"><code>C</code></th>
<th style="text-align:left"><code>max_iter</code></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:left">0.1</td>
<td style="text-align:left">10</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:left">0.1</td>
<td style="text-align:left">100</td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:left">0.1</td>
<td style="text-align:left">1000</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:left">1</td>
<td style="text-align:left">10</td>
</tr>
<tr>
<td style="text-align:center">5</td>
<td style="text-align:left">1</td>
<td style="text-align:left">100</td>
</tr>
<tr>
<td style="text-align:center">6</td>
<td style="text-align:left">1</td>
<td style="text-align:left">1000</td>
</tr>
<tr>
<td style="text-align:center">7</td>
<td style="text-align:left">10</td>
<td style="text-align:left">10</td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td style="text-align:left">10</td>
<td style="text-align:left">100</td>
</tr>
<tr>
<td style="text-align:center">9</td>
<td style="text-align:left">10</td>
<td style="text-align:left">1000</td>
</tr>
</tbody>
</table>
<p>For further information about how GridSearchCV works please refer to the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html">documentation</a>.</p>
<p>In total there will be 9 models each with different value of C and max_iter defined above, each model will be trained on the data fed into it.</p>
<p>To train with GridSearchCV we need to create GridSearchCV instances, define the number of cross-validation (cv) we want, here we set to cv=3.</p>
<pre><code>grid = GridSearchCV(estimator=model_no_tune, param_grid=parameters, cv=3, refit=True)

grid.fit(X_train, y_train)

</code></pre><p>Let’s take a look at the results</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">cv_results <span style="color:#f92672">=</span> pd<span style="color:#f92672">.</span>DataFrame(grid<span style="color:#f92672">.</span>cv_results_)
</code></pre></div><p>You can check by yourself that <code>cv_results</code> also includes the information about time required to process the data, we will ignore time-related information and just see the score, thus
<figure>
    <img src="https://orvindemsy.github.io/portfolio/images/blog/blog-3-refit/cv_result.png"/> 
</figure>
</p>
<p>Notice that there are 9 rows, each row represents model with different hyperparameter values. You can also infer which model perform the best by looking at <code>mean_test_score</code>, which should correspond to <code>rank_test_score</code></p>
<p>Alternatively, we can call <code>grid.best_score_</code> to see the best score, this will gives the best <code>mean_test_score</code> (aka. 1st place in <code>rank_test_score</code>)</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">grid<span style="color:#f92672">.</span>best_score_
</code></pre></div><p>Output:</p>
<pre><code>0.952957615277131
</code></pre><p>Plus, you can see the best parameters that corresponds to best score</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">grid<span style="color:#f92672">.</span>best_params_
</code></pre></div><p>Output:</p>
<pre><code>{'C': 10, 'max_iter': 1000}
</code></pre><h2 id="extracting-best-model">Extracting best model</h2>
<p>Fortunately, grid instance provide us with <code>best_estimator_</code> methods that return the best model with the best parameter</p>
<pre><code>best_model = grid.best_estimator_
best_model
</code></pre><pre><code>LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
</code></pre><p>See the <code>C</code> and <code>max_iter</code> values matches the above <code>grid.best_params</code></p>
<p>Now this is the part where I scratched my head the most. Recall that we did cross-validation to evaluate the best model score during grid search, and recall that <em>each set inside those cross-validation yields different set of weights</em> now if we see our weights in the <code>best_model</code></p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(best_model<span style="color:#f92672">.</span>coef_)
<span style="color:#66d9ef">print</span>(best_model<span style="color:#f92672">.</span>intercept_)
</code></pre></div><p>Output:</p>
<pre><code>[[ 4.87236201  0.38557485 -0.50462669 -0.01637815 -0.38553339 -0.78678517
  -1.57447757 -1.0836287  -0.67538905 -0.03815671 -0.40786062  3.59780421
   0.35464063 -0.18371018 -0.06740272  0.0985651   0.06214831 -0.11794136
  -0.15798064  0.02367259  0.33852914 -0.71118748  0.04939336 -0.01150091
  -0.84846646 -1.90486052 -3.16630724 -1.73183156 -2.50614262 -0.1584183 ]]
[1.65736284]
</code></pre><p>Now the question is, which set of data produce these weights?</p>
<p>To answer that we need to understand the role of <code>refit = True</code> when defining grid instance (it is set to True by default). Here’s a snippet from the documentation</p>
<blockquote>
<p><strong>refit:</strong> <em><strong>bool, str, or callable, default=True</strong></em><br>
Refit an estimator using the best found parameters on the whole dataset.</p>
</blockquote>
<p>So, roughly this is how I picture what is going on under the hood of <code>grid.fit(X_train, y_train)</code></p>
<figure>
    <img src="https://orvindemsy.github.io/portfolio/images/blog/blog-3-refit/refit_graph.png"/> 
</figure>

<h2 id="sanity-check">Sanity check</h2>
<p>Hypothesis:</p>
<blockquote>
<p>If the model was trained on the whole training data, then a new model with hyperparameters equal to those in <code>best_model</code> will gives same weights and bias values, furthermore they will give the same score when evaluated on test data.</p>
</blockquote>
<p>Let’s give it a try</p>
<p>First define new model named <code>model_sanity</code> and assign best hyperparameters value to that model, ie. C = 10 and max_iter = 1000</p>
<pre><code>model_sanity = LogisticRegression()
model_sanity.C = 10
model_sanity.max_iter = 1000
</code></pre><p>Fit the model to whole training data</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">model_sanity<span style="color:#f92672">.</span>fit(X_train, y_train)
</code></pre></div><p>Output:</p>
<pre><code>LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)`
</code></pre><p>Check whether <code>coef_</code> and <code>intercept_</code> values are the same</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span> (np<span style="color:#f92672">.</span>all(model_sanity<span style="color:#f92672">.</span>coef_ <span style="color:#f92672">==</span> best_model<span style="color:#f92672">.</span>coef_))
<span style="color:#66d9ef">print</span> (np<span style="color:#f92672">.</span>all(model_sanity<span style="color:#f92672">.</span>intercept_ <span style="color:#f92672">==</span> best_model<span style="color:#f92672">.</span>intercept_))
</code></pre></div><p>Moreover, we can check the score of <code>model_sanity</code> and <code>best_model</code> on test data, they should be equal</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;model_sanity score: </span><span style="color:#e6db74">%.5f</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span>model_sanity<span style="color:#f92672">.</span>score(X_test, y_test))
<span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#39;best_model score: </span><span style="color:#e6db74">%.5f</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span>best_model<span style="color:#f92672">.</span>score(X_test, y_test))
</code></pre></div><p>Output:</p>
<pre><code>model_sanity score: 0.96491
best_model score: 0.96491
</code></pre><p>And of course this score after hyperparameter tuning is better than score of <code>model_no_tune</code></p>
<p>And that’s it! now we know exactly what <code>refit=True</code> does in GridSearchCV instance. Currently this is my go-to routine when tuning. It’s worth noting that <code>RandomizedSearchCV</code> also has the same methods and attribute that behave the same way as <code>GridSearchCV</code>.</p>
<!-- raw HTML omitted -->
<ul class="pa0">
  
   <li class="list">
     <a href="https://orvindemsy.github.io/portfolio/tags/" class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif"></a>
   </li>
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




  <div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
    <p class="f5 b mb3">Related</p>
    <ul class="pa0 list">
	   
	     <li  class="mb2">
          <a href="https://orvindemsy.github.io/portfolio/blog/blog-2/">KL divergence on iris dataset</a>
        </li>
	    
	     <li  class="mb2">
          <a href="https://orvindemsy.github.io/portfolio/blog/blog-1/">Data Alignment using Euclidean Alignment</a>
        </li>
	    
    </ul>
</div>

</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://orvindemsy.github.io/portfolio/" >
    &copy;  Orvin Demsy 2020 
  </a>
    <div>







<a href="https://www.linkedin.com/in/orvin-demsy" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>


<a href="github.com/orvindemsy" target="_blank" class="link-transition github link dib z-999 pt3 pt0-l mr1" title="Github link" rel="noopener" aria-label="follow on Github——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 512 512;" version="1.1" viewBox="0 0 512 512" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
  <path d="M256,32C132.3,32,32,134.8,32,261.7c0,101.5,64.2,187.5,153.2,217.9c11.2,2.1,15.3-5,15.3-11.1   c0-5.5-0.2-19.9-0.3-39.1c-62.3,13.9-75.5-30.8-75.5-30.8c-10.2-26.5-24.9-33.6-24.9-33.6c-20.3-14.3,1.5-14,1.5-14   c22.5,1.6,34.3,23.7,34.3,23.7c20,35.1,52.4,25,65.2,19.1c2-14.8,7.8-25,14.2-30.7c-49.7-5.8-102-25.5-102-113.5   c0-25.1,8.7-45.6,23-61.6c-2.3-5.8-10-29.2,2.2-60.8c0,0,18.8-6.2,61.6,23.5c17.9-5.1,37-7.6,56.1-7.7c19,0.1,38.2,2.6,56.1,7.7   c42.8-29.7,61.5-23.5,61.5-23.5c12.2,31.6,4.5,55,2.2,60.8c14.3,16.1,23,36.6,23,61.6c0,88.2-52.4,107.6-102.3,113.3   c8,7.1,15.2,21.1,15.2,42.5c0,30.7-0.3,55.5-0.3,63c0,6.1,4,13.3,15.4,11C415.9,449.1,480,363.1,480,261.7   C480,134.8,379.7,32,256,32z"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>







</div>
  </div>
</footer>

    

  <script src="https://orvindemsy.github.io/portfolio/dist/js/app.3fc0f988d21662902933.js"></script>


  </body>
</html>
